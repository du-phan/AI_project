{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    \n",
    "    def __init__(self, layer_node): #layer_node is a list contains the number of nodes in each layer\n",
    "        self.num_layer = len(layer_node)\n",
    "        self.layer_node = layer_node\n",
    "        self.input_node = []\n",
    "        #self.node = [ np.random.randn(num_node,1) for num_node in layer_node ]\n",
    "        self.weights = [ np.random.randn(next_node,previous_node+1) for next_node, previous_node in zip(layer_node[1:],layer_node[:-1]) ]\n",
    "        \n",
    "    def add_input_node(self,input_vector): #must be of size (n,1)\n",
    "        if len(input_vector) == self.layer_node[0]: \n",
    "            self.input_node = np.append([[1]],input_vector, axis=0) # add bias node\n",
    "        else:\n",
    "            print \"Input vector length invalid: given len {1}, need len {0}\".format(self.layer_node[0], len(input_vector))\n",
    "            \n",
    "    def forward_propagation(self):\n",
    "        output_vector = self.input_node\n",
    "        for weight in self.weights: \n",
    "            #print weight.shape\n",
    "            #print output_vector.shape\n",
    "            s = np.dot(weight, output_vector)\n",
    "            output_vector = np.append([[1]], output_transformation(s), axis=0) # add bias node -> size (n+1,1)\n",
    "        return output_vector[1:] # we omit the bias node \n",
    "        \n",
    "    def backpropagation(self,input_vector, output_vector):\n",
    "        s = [] # vector before transformation \n",
    "        x = [np.append([[1]],input_vector, axis=0)] # vector after transformation\n",
    "        sensitivity = [ np.zeros([1,i]) for i in self.layer_node ]\n",
    "        \n",
    "        #feedforward, save all the node coefs of each layer\n",
    "        for weight in self.weights:\n",
    "            s.append(np.dot(weight, x[-1]))\n",
    "            x.append(np.append([[1]], output_transformation(s[-1]), axis=0))\n",
    "            \n",
    "        sensitivity[-1] = 2*(x[-1][1:] - output_vector) # omit the bias node \n",
    "        \n",
    "        #backpropagation, compute sensitivity backward\n",
    "        for layer_index in xrange(2, self.num_layer+1):\n",
    "            w = self.weights[-layer_index+1]\n",
    "            #print w\n",
    "            #print w.shape\n",
    "            print sensitivity[-layer_index+1].shape\n",
    "            \n",
    "            sensitivity[-layer_index] = (np.dot(w.T,sensitivity[-layer_index+1]))[1:] #excluding the bias componnent which has the index 0\n",
    "            \n",
    "        return sensitivity\n",
    "        \n",
    "         \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_transformation(z):\n",
    "    return z # linear regression -> identity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_signal = np.array([[1],[2]])\n",
    "input_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Network([2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.add_input_node(input_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.43388697]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward_propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.37232878 -0.74908326  1.20911348  0.51379664]]\n",
      "(1, 4)\n",
      "(1, 1)\n",
      "[[-0.54408268 -0.53440993 -1.54756976]\n",
      " [-0.4904078   0.85622078 -0.42948791]\n",
      " [-0.00864444 -0.36055841  0.45329494]]\n",
      "(3, 3)\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "s = net.backpropagation(input_signal,np.array([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-18.92030515],\n",
       "        [-13.20832069]]), array([[ 11.33529717],\n",
       "        [-18.29657848],\n",
       "        [ -7.77488691]]), array([[-15.13222607]])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

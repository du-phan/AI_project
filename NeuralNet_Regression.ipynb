{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import math\n",
    "from PIL import Image\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " np.random.randn(next_node,previous_node+1)\n",
    " np.random.normal(0,0.3,(next_node,previous_node+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    \n",
    "    def __init__(self, layer_node): #layer_node is a list contains the number of nodes in each layer\n",
    "        self.num_layer = len(layer_node)\n",
    "        self.layer_node = layer_node\n",
    "        self.input_node = []\n",
    "        self.weights = [  np.random.randn(next_node,previous_node+1) for next_node, previous_node in zip(layer_node[1:],layer_node[:-1]) ]\n",
    "        \n",
    "    def add_input_node(self,input_vector): #must be of size (n,1)\n",
    "        if len(input_vector) == self.layer_node[0]: \n",
    "            self.input_node = np.append([[1]],input_vector, axis=0) # add bias node\n",
    "        else:\n",
    "            print \"Input vector length invalid: given len {1}, need len {0}\".format(self.layer_node[0], len(input_vector))\n",
    "            \n",
    "    def forward_propagation(self):\n",
    "        output_value = self.input_node\n",
    "        for weight in self.weights: \n",
    "            s = np.dot(weight, output_value)\n",
    "            output_value = np.append([[1]], activation_function(s), axis=0) # add bias node -> size (n+1,1)\n",
    "        return output_activation_function(output_value[1:][0][0]) # we omit the bias node \n",
    "        \n",
    "    def backpropagation(self,input_vector, output_vector):\n",
    "        s = [] # vector before entering node\n",
    "        x = [np.append([[1]],input_vector, axis=0)] # vector after entering node\n",
    "        sensitivity = [ np.zeros([1,i]) for i in self.layer_node[1:] ]\n",
    "        #print len(sensitivity)\n",
    "        \n",
    "        #feedforward, save all the node coefs of each layer\n",
    "        for weight in self.weights:\n",
    "            s.append(np.dot(weight, x[-1]))\n",
    "            #print \"back\"\n",
    "            x.append(np.append([[1]], activation_function(s[-1]), axis=0))\n",
    "        sensitivity[-1] = 2.0*(x[-1][1:] - output_vector)*(1-np.square(x[-1][1:])) # omit the bias node \n",
    "        \n",
    "        #backpropagation, compute sensitivity backward\n",
    "        for layer_index in xrange(2, self.num_layer):\n",
    "            w = self.weights[-layer_index+1]            \n",
    "            sensitivity[-layer_index] = (1-np.square(x[-layer_index][1:]))*(np.dot(w.T,sensitivity[-layer_index+1]))[1:] #excluding the bias componnent which has the index 0 \n",
    "        return x, sensitivity\n",
    "    \n",
    "    def SGD(self, training_data, testing_data, eta, epochs, visualize = True): #stochastic gradient descent\n",
    "        MSE_list = []\n",
    "        predicted_result = []\n",
    "        result_df = None\n",
    "        for epoch in xrange(epochs): \n",
    "            MSE = 0 \n",
    "            gradient = [np.zeros(w.shape) for w in self.weights]\n",
    "            #gradient = [ np.random.randn(next_node,previous_node+1) \n",
    "                            #for next_node, previous_node in zip(self.layer_node[1:],self.layer_node[:-1])]\n",
    "            for index, row in training_data.iterrows():\n",
    "                vector = np.array(row).reshape(3,1) \n",
    "                input_vector, output_vector = vector[:2], vector[2:]\n",
    "                x, sensitivity = self.backpropagation(input_vector, output_vector)\n",
    "\n",
    "                for l in xrange(len(gradient)):\n",
    "                    #print x[l].shape\n",
    "                    #print sensitivity[l].shape\n",
    "                    gradient[l] = np.dot(sensitivity[l],np.transpose(x[l]))\n",
    "                    self.weights[l] = self.weights[l] - eta*gradient[l]\n",
    "            \n",
    "            MSE, predicted_result = self.evaluate(testing_data)\n",
    "            MSE_list.append(MSE)\n",
    "     \n",
    "        print \"MSE = \", MSE_list[-1]\n",
    "        if visualize: \n",
    "            result_df = visualization(testing_data,predicted_result, MSE_list)\n",
    "        return MSE_list, predicted_result, result_df\n",
    "    \n",
    "    def evaluate(self,testing_data):\n",
    "        MSE = 0\n",
    "        predicted_result = []\n",
    "        for index, row in testing_data.iterrows():\n",
    "            vector = np.array(row).reshape(3,1) \n",
    "            input_vector, output_value = vector[:2], vector[2:]\n",
    "            self.add_input_node(input_vector)\n",
    "            predicted_value = self.forward_propagation()\n",
    "            predicted_result.append(predicted_value)\n",
    "            MSE += np.square(predicted_value - output_value)\n",
    "        MSE = float(MSE)/testing_data.shape[0]\n",
    "        return MSE, predicted_result\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_function(z):\n",
    "    return np.tanh(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_activation_function(z):\n",
    "    return z # linear regression -> identity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_pixel(oldValue, oldRange, oldMin):\n",
    "    #oldRange = 1 \n",
    "    newRange = 255 \n",
    "    newMin = 0\n",
    "    #oldMin = 0\n",
    "    newValue = (((oldValue - oldMin) * newRange) / oldRange) + newMin #oldMin = newMin = 0\n",
    "    return math.ceil(newValue)\n",
    "\n",
    "def visualization(df, predicted_result, MSE): \n",
    "    data = df.copy()\n",
    "    data['Predicted'] = predicted_result\n",
    "    new_value = data['Value'].apply(convert_to_pixel, args=(1,0))\n",
    "    \n",
    "    \n",
    "    min_predicted = data['Predicted'].min()\n",
    "    max_predicted = data['Predicted'].max()\n",
    "    \n",
    "    new_predicted = data['Predicted'].apply(convert_to_pixel, args=(max_predicted-min_predicted,min_predicted))\n",
    "    data.Value = new_value\n",
    "    data.Predicted = new_predicted\n",
    "    plt.plot(MSE)\n",
    "    plt.title('MSE plot')\n",
    "    data.plot(kind='scatter',x='x',y='y',c='Value', title=\"True Plot\")\n",
    "    data.plot(kind='scatter',x='x',y='y',c='Predicted', title=\"Predicted Plot\")\n",
    "    plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_float(df): \n",
    "    new_df = df.copy()\n",
    "    return new_df.applymap(lambda x: float(x.replace(',','.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def z_score(df):\n",
    "    new_df = df.copy()\n",
    "    new_df.x = (new_df.x - new_df.x.mean())/new_df.x.std(ddof=0)\n",
    "    new_df.y = (new_df.y - new_df.y.mean())/new_df.y.std(ddof=0)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('donneespb3.txt', sep=' ', header=None)\n",
    "df.columns = ['x','y','Value']\n",
    "df = str_to_float(df)\n",
    "df = z_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000e+03</td>\n",
       "      <td>3.000000e+03</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.588877e-15</td>\n",
       "      <td>-1.724546e-16</td>\n",
       "      <td>0.473798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000167e+00</td>\n",
       "      <td>1.000167e+00</td>\n",
       "      <td>0.350761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.742213e+00</td>\n",
       "      <td>-1.709756e+00</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.563515e-01</td>\n",
       "      <td>-8.625151e-01</td>\n",
       "      <td>0.127083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.924538e-02</td>\n",
       "      <td>6.958319e-03</td>\n",
       "      <td>0.441669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.507667e-01</td>\n",
       "      <td>8.673395e-01</td>\n",
       "      <td>0.825775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.737918e+00</td>\n",
       "      <td>1.743687e+00</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x             y        Value\n",
       "count  3.000000e+03  3.000000e+03  3000.000000\n",
       "mean  -1.588877e-15 -1.724546e-16     0.473798\n",
       "std    1.000167e+00  1.000167e+00     0.350761\n",
       "min   -1.742213e+00 -1.709756e+00     0.000010\n",
       "25%   -8.563515e-01 -8.625151e-01     0.127083\n",
       "50%    2.924538e-02  6.958319e-03     0.441669\n",
       "75%    8.507667e-01  8.673395e-01     0.825775\n",
       "max    1.737918e+00  1.743687e+00     0.999990"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neural_net = Network([2,50,1])\n",
    "t0 = time.clock()\n",
    "MSE, predicted_result, result = neural_net.SGD(training_data = data, testing_data = data, \n",
    "                                             eta = 0.01, epochs = 3000)\n",
    "print \"Processing time: {0:.2f} minutes\".format((time.clock() - t0)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, above we have used training data as testing data, and that did not reflect the quality of our model. The neural network is known for its overfitting problem, thus the low MSE received above is not trustworthy. \n",
    "#### We will now use cross-validation to assess our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('donneespb3.txt', sep=' ', header=None)\n",
    "data.columns = ['x','y','Value']\n",
    "data = str_to_float(data)\n",
    "data = z_score(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kfold_neural_net(neural_net,algorithm, n_folds, data, epochs):\n",
    "    kf = KFold( n=data.shape[0], n_folds=n_folds, shuffle=False,random_state=None)\n",
    "    cumulative_MSE = 0\n",
    "    counter = 1\n",
    "    for train_index, test_index in kf:\n",
    "        neural_net = Network(neural_net)\n",
    "        train_set = data.iloc[train_index,:]\n",
    "        test_set = data.iloc[test_index,:]\n",
    "        print \"Iteration {0}: \".format(counter),\n",
    "        MSE_list, predicted_result, d = algorithm.SGD(training_data = train_set, testing_data = test_set, \n",
    "                    eta = 0.01, epochs = epochs, visualize = False)\n",
    "        cumulative_MSE += MSE_list[-1]\n",
    "        counter+=1\n",
    "    print\n",
    "    print \"Average MSE = \", cumulative_MSE/float(n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:  MSE =  0.122348922926\n",
      "Iteration 2:  MSE =  0.131017805661\n",
      "Iteration 3:  MSE =  0.125197093595\n",
      "Iteration 4:  MSE =  0.109476278519\n",
      "Iteration 5:  MSE =  0.123734955399\n",
      "Iteration 6:  MSE =  0.114813869345\n",
      "Iteration 7:  MSE =  0.108268286855\n",
      "Iteration 8:  MSE =  0.099563237558\n",
      "Iteration 9:  MSE =  0.106539011303\n",
      "Iteration 10:  MSE =  0.0973187028448\n",
      "\n",
      "Average MSE =  0.113827816401\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold_neural_net(neural_net = [2,50,1], n_folds = 10, data = data, epochs = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

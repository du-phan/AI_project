{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named matplotlib.pyplot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-67154fb84d7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named matplotlib.pyplot"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import math\n",
    "from PIL import Image\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    \n",
    "    def __init__(self, layer_node): #layer_node is a list contains the number of nodes in each layer\n",
    "        self.num_layer = len(layer_node)\n",
    "        self.layer_node = layer_node\n",
    "        self.input_node = []\n",
    "        #self.node = [ np.random.randn(num_node,1) for num_node in layer_node ]\n",
    "        self.weights = [ np.random.randn(next_node,previous_node+1) for next_node, previous_node in zip(layer_node[1:],layer_node[:-1]) ]\n",
    "        \n",
    "    def add_input_node(self,input_vector): #must be of size (n,1)\n",
    "        if len(input_vector) == self.layer_node[0]: \n",
    "            self.input_node = np.append([[1]],input_vector, axis=0) # add bias node\n",
    "        else:\n",
    "            print \"Input vector length invalid: given len {1}, need len {0}\".format(self.layer_node[0], len(input_vector))\n",
    "            \n",
    "    def forward_propagation(self):\n",
    "        output_value = self.input_node\n",
    "        for weight in self.weights: \n",
    "            s = np.dot(weight, output_value)\n",
    "            output_value = np.append([[1]], activation_function(s), axis=0) # add bias node -> size (n+1,1)\n",
    "        return output_activation_function(output_value[1:][0][0]) # we omit the bias node \n",
    "        \n",
    "    def backpropagation(self,input_vector, output_vector):\n",
    "        s = [] # vector before entering node\n",
    "        x = [np.append([[1]],input_vector, axis=0)] # vector after entering node\n",
    "        sensitivity = [ np.zeros([1,i]) for i in self.layer_node[1:] ]\n",
    "        #print len(sensitivity)\n",
    "        \n",
    "        #feedforward, save all the node coefs of each layer\n",
    "        for weight in self.weights:\n",
    "            s.append(np.dot(weight, x[-1]))\n",
    "            #print \"back\"\n",
    "            x.append(np.append([[1]], activation_function(s[-1]), axis=0))\n",
    "        sensitivity[-1] = 2.0*(x[-1][1:] - output_vector)*(1-np.square(x[-1][1:])) # omit the bias node \n",
    "        \n",
    "        #backpropagation, compute sensitivity backward\n",
    "        for layer_index in xrange(2, self.num_layer):\n",
    "            w = self.weights[-layer_index+1]            \n",
    "            sensitivity[-layer_index] = (1-np.square(x[-layer_index][1:]))*(np.dot(w.T,sensitivity[-layer_index+1]))[1:] #excluding the bias componnent which has the index 0\n",
    "            \n",
    "        return x, sensitivity\n",
    "    \n",
    "    def SGD(self, training_data, testing_data, eta, epochs): #stochastic gradient descent\n",
    "        MSE_list = []\n",
    "        predicted_result = []\n",
    "        for epoch in xrange(epochs): \n",
    "            MSE = 0 \n",
    "            gradient = [np.zeros(w.shape) for w in self.weights]\n",
    "            #gradient = [ np.random.randn(next_node,previous_node+1) \n",
    "                            #for next_node, previous_node in zip(self.layer_node[1:],self.layer_node[:-1])]\n",
    "            for index, row in training_data.iterrows():\n",
    "                vector = np.array(row).reshape(3,1) \n",
    "                input_vector, output_vector = vector[:2], vector[2:]\n",
    "                x, sensitivity = self.backpropagation(input_vector, output_vector)\n",
    "\n",
    "                for l in xrange(len(gradient)):\n",
    "                    #print x[l].shape\n",
    "                    #print sensitivity[l].shape\n",
    "                    gradient[l] = np.dot(sensitivity[l],np.transpose(x[l]))\n",
    "                    self.weights[l] = self.weights[l] - eta*gradient[l]\n",
    "            \n",
    "            MSE, predicted_result = self.evaluate(testing_data)\n",
    "            MSE_list.append(MSE)\n",
    "     \n",
    "        print \"MSE = \", MSE_list[-1]\n",
    "        data = visualization(testing_data,predicted_result, MSE_list)\n",
    "        return MSE_list, predicted_result, data\n",
    "    \n",
    "    \n",
    "    \n",
    "    def evaluate(self,testing_data):\n",
    "        MSE = 0\n",
    "        predicted_result = []\n",
    "        for index, row in testing_data.iterrows():\n",
    "            vector = np.array(row).reshape(3,1) \n",
    "            input_vector, output_value = vector[:2], vector[2:]\n",
    "            self.add_input_node(input_vector)\n",
    "            predicted_value = self.forward_propagation()\n",
    "            predicted_result.append(predicted_value)\n",
    "            MSE += np.square(predicted_value - output_value)\n",
    "        return float(MSE)/testing_data.shape[0], predicted_result\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_function(z):\n",
    "    return np.tanh(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_activation_function(z):\n",
    "    return z # linear regression -> identity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_pixel(oldValue):\n",
    "    oldRange = 1 \n",
    "    newRange = 255 \n",
    "    newValue = (((oldValue - 0) * newRange) / oldRange) + 0 #oldMin = newMin = 0\n",
    "    return math.ceil(newValue)\n",
    "\n",
    "def visualization(df, predicted_result, MSE): \n",
    "    data = df.copy()\n",
    "\n",
    "    data['Predicted'] = predicted_result\n",
    "    new_value = data['Value'].apply(convert_to_pixel)\n",
    "    new_predicted = data['Predicted'].apply(convert_to_pixel)\n",
    "    data.Value = new_value\n",
    "    data.Predicted = new_predicted\n",
    "    plt.plot(MSE)\n",
    "    plt.title('MSE plot')\n",
    "    data.plot(kind='scatter',x='x',y='y',c='Value', title=\"True Plot\")\n",
    "    data.plot(kind='scatter',x='x',y='y',c='Predicted', title=\"Predicted Plot\")\n",
    "    plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_float(df): \n",
    "    new_df = df.copy()\n",
    "    return new_df.applymap(lambda x: float(x.replace(',','.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def z_score(df):\n",
    "    new_df = df.copy()\n",
    "    new_df.x = (new_df.x - new_df.x.mean())/new_df.x.std(ddof=0)\n",
    "    new_df.y = (new_df.y - new_df.y.mean())/new_df.y.std(ddof=0)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('donneespb3.txt', sep=' ', header=None)\n",
    "data.columns = ['x','y','Value']\n",
    "data = str_to_float(data)\n",
    "data = z_score(data)\n",
    "\n",
    "train = data.iloc[:2700]\n",
    "#train.shape\n",
    "\n",
    "test = data.iloc[2700:]\n",
    "#test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neural_net = Network([2,50,1])\n",
    "\n",
    "t0 = time.clock()\n",
    "MSE, predicted_result, data = neural_net.SGD(training_data = data, testing_data = data, eta = 0.01, epochs = 2000)\n",
    "print \"Processing time: {0:.2f} minutes\".format((time.clock() - t0)/60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

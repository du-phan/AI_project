{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    \n",
    "    def __init__(self, layer_node): #layer_node is a list contains the number of nodes in each layer\n",
    "        self.num_layer = len(layer_node)\n",
    "        self.layer_node = layer_node\n",
    "        self.input_node = []\n",
    "        self.weights = [ np.random.randn(next_node,previous_node+1) for next_node, previous_node in zip(layer_node[1:],layer_node[:-1]) ]\n",
    "        \n",
    "    def add_input_node(self,input_vector): #must be of size (n,1)\n",
    "        if len(input_vector) == self.layer_node[0]: \n",
    "            self.input_node = np.append([[1]],input_vector, axis=0) # add bias node\n",
    "        else:\n",
    "            print \"Input vector length invalid: given len {1}, need len {0}\".format(self.layer_node[0], len(input_vector))\n",
    "            \n",
    "    def forward_propagation(self):\n",
    "        output_value = self.input_node\n",
    "        for weight in self.weights: \n",
    "            s = np.dot(weight, output_value)\n",
    "            output_value = np.append([[1]], activation_function(s), axis=0) # add bias node -> size (n+1,1)\n",
    "        return np.sign(output_value[1:][0][0]) # we omit the bias node \n",
    "        \n",
    "    def backpropagation(self,input_vector, output_vector):\n",
    "        s = [] # vector before entering activation function\n",
    "        x = [np.append([[1]],input_vector, axis=0)] # vector after entering activation function\n",
    "        sensitivity = [ np.zeros([1,i]) for i in self.layer_node[1:] ]\n",
    "        \n",
    "        #feedforward, save all the node coefs of each layer\n",
    "        for weight in self.weights:\n",
    "            s.append(np.dot(weight, x[-1]))\n",
    "            x.append(np.append([[1]], activation_function(s[-1]), axis=0))\n",
    "        sensitivity[-1] = 2.0*(x[-1][1:] - output_vector)*(1-np.square(x[-1][1:])) # omit the bias node \n",
    "        \n",
    "        #backpropagation, compute sensitivity backward\n",
    "        for layer_index in xrange(2, self.num_layer):\n",
    "            w = self.weights[-layer_index+1]\n",
    "            #excluding the bias componnent which has the index 0\n",
    "            sensitivity[-layer_index] = (1-np.square(x[-layer_index][1:]))*(np.dot(w.T,sensitivity[-layer_index+1]))[1:] \n",
    "        return x, sensitivity\n",
    "    \n",
    "    def SGD(self, training_data, testing_data, eta, epochs, print_message=True, visualize=True): #stochastic gradient descent\n",
    "        error_ratio_list = []\n",
    "        error_ratio = 0\n",
    "        error_count = 0\n",
    "        predicted_result = []\n",
    "        result_df = None\n",
    "        \n",
    "        for epoch in xrange(epochs): \n",
    "            gradient = [np.zeros(w.shape) for w in self.weights]\n",
    "            \n",
    "            for index, row in training_data.iterrows():\n",
    "                vector = np.array(row).reshape(3,1) \n",
    "                input_vector, output_vector = vector[:2], vector[2:]\n",
    "                x, sensitivity = self.backpropagation(input_vector, output_vector)\n",
    "                \n",
    "                for l in xrange(len(gradient)):\n",
    "                    gradient[l] = np.dot(sensitivity[l],np.transpose(x[l]))\n",
    "                    self.weights[l] = self.weights[l] - eta*gradient[l]\n",
    "                    \n",
    "            error_ratio, error_count, predicted_result = self.evaluate(testing_data)\n",
    "            error_ratio_list.append(error_ratio)\n",
    "            \n",
    "        if print_message:\n",
    "            print \"Error count = {0}/{1}\".format(error_count[0,0], testing_data.shape[0])\n",
    "            print \"Error ratio = \", error_ratio_list[-1]\n",
    "\n",
    "        if visualize: \n",
    "            result_df = visualization(testing_data, error_ratio_list, predicted_result)\n",
    "        \n",
    "        return error_ratio_list, predicted_result, result_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    def evaluate(self,testing_data):\n",
    "        error_count = 0\n",
    "        predicted_result = []\n",
    "        for index, row in testing_data.iterrows():\n",
    "            vector = np.array(row).reshape(3,1) \n",
    "            input_vector, output_vector = vector[:2], vector[2:]\n",
    "            self.add_input_node(input_vector)\n",
    "            predicted_value = self.forward_propagation()\n",
    "            predicted_result.append(predicted_value)\n",
    "            error_count += predicted_value != output_vector\n",
    "        return float(error_count)/testing_data.shape[0], error_count, predicted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualization(df, MSE, predicted_result): \n",
    "    result_df = df.copy()\n",
    "    result_df['Predicted'] = predicted_result\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(MSE)\n",
    "    plt.title(\"Error Ratio Plot\")\n",
    "    \n",
    "    colormap = np.array(['b','b' ,'r'])\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.scatter(result_df.x, result_df.y, c=colormap[result_df.Class], s=40)\n",
    "    plt.title(\"True Plot\")\n",
    "    \n",
    "    plt.figure(3)\n",
    "    plt.scatter(result_df.x, result_df.y, c=colormap[result_df.Predicted], s=40)\n",
    "    plt.title(\"Predicted Plot\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_function(z): \n",
    "    return np.tanh(z) # sigmoid function tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_float(df): \n",
    "    new_df = df.copy()\n",
    "    return new_df.applymap(lambda x: float(x.replace(',','.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def z_score(df):\n",
    "    new_df = df.copy()\n",
    "    new_df.x = (new_df.x - new_df.x.mean())/new_df.x.std(ddof=0)\n",
    "    new_df.y = (new_df.y - new_df.y.mean())/new_df.y.std(ddof=0)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_df(file_link):\n",
    "    df = pd.read_csv(file_name,sep=' ',header=None)\n",
    "    df.columns = ['x','y','Value']\n",
    "    df = str_to_float(df)\n",
    "    df = z_score(df) \n",
    "    binary_code = [np.sign(x-.5) for x in df.Value] \n",
    "    df['Class'] = binary_code \n",
    "    df = df.drop('Value',1)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = create_df(file_name=\"donneespb4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-bfaea01c16d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mMSE_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Processing time: {0} seconds\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-725e2fbded9c>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, training_data, testing_data, eta, epochs, print_message, visualize)\u001b[0m\n\u001b[0;32m     54\u001b[0m                     \u001b[0mgradient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0merror_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m             \u001b[0merror_ratio_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-725e2fbded9c>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, testing_data)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0minput_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_input_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mpredicted_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[0mpredicted_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0merror_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpredicted_value\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0moutput_vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-725e2fbded9c>\u001b[0m in \u001b[0;36mforward_propagation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0moutput_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# add bias node -> size (n+1,1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# we omit the bias node\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tphan.ENSC.001\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\numpy\\lib\\function_base.pyc\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   4142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4143\u001b[0m     \"\"\"\n\u001b[1;32m-> 4144\u001b[1;33m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4146\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = Network([2,30,1])\n",
    "t0 = time.clock()\n",
    "MSE_list, predicted_result, result_df = net.SGD(df,df,0.01,200)\n",
    "print \"Processing time: {0} seconds\".format((time.clock() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10-fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kfold_neural_net(neural_net, n_folds, data, eta, epochs, print_message=True):\n",
    "    kf = KFold( n=data.shape[0], n_folds=n_folds, shuffle=False,random_state=None)\n",
    "    cumulative_MSE = 0\n",
    "    counter = 1 \n",
    "    for train_index, test_index in kf:\n",
    "        net = Network(neural_net)\n",
    "        train_set = data.iloc[train_index,:]\n",
    "        test_set = data.iloc[test_index,:]\n",
    "        if print_message:\n",
    "            print \"----Iteration {0}----\".format(counter)\n",
    "        MSE_list, predicted_result, result_df = net.SGD(training_data = train_set, testing_data = test_set, \n",
    "                    eta = eta, epochs = epochs, print_message = print_message,visualize = False)\n",
    "        cumulative_MSE += MSE_list[-1]\n",
    "        counter += 1\n",
    "        if print_message: \n",
    "            print\n",
    "        \n",
    "    average_error_ratio = cumulative_MSE/float(n_folds)\n",
    "    if print_message: \n",
    "        print \"Average error ratio = \", average_error_ratio\n",
    "    return average_error_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 1----\n",
      "Error count = 15/300\n",
      "Error ratio =  0.05\n",
      "\n",
      "----Iteration 2----\n",
      "Error count = 15/300\n",
      "Error ratio =  0.05\n",
      "\n",
      "----Iteration 3----\n",
      "Error count = 23/300\n",
      "Error ratio =  0.0766666666667\n",
      "\n",
      "----Iteration 4----\n",
      "Error count = 40/300\n",
      "Error ratio =  0.133333333333\n",
      "\n",
      "----Iteration 5----\n",
      "Error count = 10/300\n",
      "Error ratio =  0.0333333333333\n",
      "\n",
      "----Iteration 6----\n",
      "Error count = 8/300\n",
      "Error ratio =  0.0266666666667\n",
      "\n",
      "----Iteration 7----\n",
      "Error count = 13/300\n",
      "Error ratio =  0.0433333333333\n",
      "\n",
      "----Iteration 8----\n",
      "Error count = 5/300\n",
      "Error ratio =  0.0166666666667\n",
      "\n",
      "----Iteration 9----\n",
      "Error count = 42/300\n",
      "Error ratio =  0.14\n",
      "\n",
      "----Iteration 10----\n",
      "Error count = 40/300\n",
      "Error ratio =  0.133333333333\n",
      "\n",
      "Average error ratio =  0.0703333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07033333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_neural_net(neural_net=[2,30,1], n_folds=10,data=df,eta=0.01,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters seletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_parameter_df(max_learning_rate, min_learning_rate, max_neuron_num, min_neuron_num): \n",
    "    learning_rate = np.linspace(min_learning_rate, max_learning_rate, 10)\n",
    "    neuron_num = range(min_neuron_num, max_neuron_num,10)[1:] #ignore first value, which is 0\n",
    "    \n",
    "    learning_rate_lst = []\n",
    "    for x in xrange(len(neuron_num)):\n",
    "        learning_rate_lst.extend(learning_rate)\n",
    "    \n",
    "    neuron_num_list = []\n",
    "    for num in neuron_num:\n",
    "        temp_list = [num] * len(learning_rate)\n",
    "        neuron_num_list.extend(temp_list)\n",
    "    \n",
    "    parameter_df = pd.DataFrame(columns=['Neuron_number','Learning_rate','Error ratio'])\n",
    "    parameter_df['Neuron_number'] = neuron_num_list\n",
    "    parameter_df['Learning_rate'] = learning_rate_lst\n",
    "    \n",
    "    return parameter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameter_df = create_parameter_df(max_learning_rate=0.1, min_learning_rate=0.001, max_neuron_num=55, min_neuron_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neuron_number</th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>Error ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.012</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.045</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neuron_number  Learning_rate Error ratio\n",
       "0             10          0.001         NaN\n",
       "1             10          0.012         NaN\n",
       "2             10          0.023         NaN\n",
       "3             10          0.034         NaN\n",
       "4             10          0.045         NaN"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parameter_testing(df, parameter_df):\n",
    "    new_parameter_df = parameter_df.copy()\n",
    "    min_error_ratio = np.Inf\n",
    "    best_row = None\n",
    "    for index, row in new_parameter_df.iterrows():\n",
    "        print \"Calculating ({0}/{1})...\".format(index+1,new_parameter_df.shape[0]) \n",
    "        print \n",
    "        sys.stdout.flush()\n",
    "        time.sleep(.2) \n",
    "        \n",
    "        layers = [2,row.Neuron_number,1]\n",
    "        average_error_ratio = kfold_neural_net(neural_net=layers, n_folds=10, data=df, eta=row.Learning_rate, epochs= 20, \n",
    "                                      print_message=False)\n",
    "        row.Error_ratio = average_error_ratio\n",
    "        \n",
    "        if average_error_ratio < min_error_ratio: \n",
    "            min_error_ratio = average_error_ratio\n",
    "            best_row = row \n",
    "            print \"New best error ratio: \",average_error_ratio\n",
    "            print \"   Number of neurons in the hidden layer: \", row.Neuron_number\n",
    "            print \"   Learning rate: \", row.Learning_rate\n",
    "            print\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(.2) \n",
    "    \n",
    "    print \"----------------------------------------------------------\"\n",
    "    print \"Best error ratio: \",min_error_ratio\n",
    "    print \"Number of neurons in the hidden layer: \", best_row.Neuron_number\n",
    "    print \"Learning rate: \", best_row.Learning_rate\n",
    "    print \"----------------------------------------------------------\"\n",
    "        \n",
    "    return new_parameter_df, best_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating (1/50)...\n",
      "\n",
      "New best error ratio:  0.170333333333\n",
      "   Number of neurons in the hidden layer:  10\n",
      "   Learning rate:  0.001\n",
      "\n",
      "Calculating (2/50)...\n",
      "\n",
      "New best error ratio:  0.0316666666667\n",
      "   Number of neurons in the hidden layer:  10\n",
      "   Learning rate:  0.012\n",
      "\n",
      "Calculating (3/50)...\n",
      "\n",
      "New best error ratio:  0.0223333333333\n",
      "   Number of neurons in the hidden layer:  10\n",
      "   Learning rate:  0.023\n",
      "\n",
      "Calculating (4/50)...\n",
      "\n",
      "Calculating (5/50)...\n",
      "\n",
      "Calculating (6/50)...\n",
      "\n",
      "Calculating (7/50)...\n",
      "\n",
      "Calculating (8/50)...\n",
      "\n",
      "Calculating (9/50)...\n",
      "\n",
      "Calculating (10/50)...\n",
      "\n",
      "Calculating (11/50)...\n",
      "\n",
      "Calculating (12/50)...\n",
      "\n",
      "New best error ratio:  0.013\n",
      "   Number of neurons in the hidden layer:  20\n",
      "   Learning rate:  0.012\n",
      "\n",
      "Calculating (13/50)...\n",
      "\n",
      "Calculating (14/50)...\n",
      "\n",
      "Calculating (15/50)...\n",
      "\n",
      "Calculating (16/50)...\n",
      "\n",
      "Calculating (17/50)...\n",
      "\n",
      "Calculating (18/50)...\n",
      "\n",
      "Calculating (19/50)...\n",
      "\n",
      "Calculating (20/50)...\n",
      "\n",
      "Calculating (21/50)...\n",
      "\n",
      "Calculating (22/50)...\n",
      "\n",
      "New best error ratio:  0.0123333333333\n",
      "   Number of neurons in the hidden layer:  30\n",
      "   Learning rate:  0.012\n",
      "\n",
      "Calculating (23/50)...\n",
      "\n",
      "Calculating (24/50)...\n",
      "\n",
      "Calculating (25/50)...\n",
      "\n",
      "Calculating (26/50)...\n",
      "\n",
      "Calculating (27/50)...\n",
      "\n",
      "Calculating (28/50)...\n",
      "\n",
      "Calculating (29/50)...\n",
      "\n",
      "Calculating (30/50)...\n",
      "\n",
      "Calculating (31/50)...\n",
      "\n",
      "Calculating (32/50)...\n",
      "\n",
      "Calculating (33/50)...\n",
      "\n",
      "Calculating (34/50)...\n",
      "\n",
      "Calculating (35/50)...\n",
      "\n",
      "Calculating (36/50)...\n",
      "\n",
      "Calculating (37/50)...\n",
      "\n",
      "Calculating (38/50)...\n",
      "\n",
      "Calculating (39/50)...\n",
      "\n",
      "Calculating (40/50)...\n",
      "\n",
      "Calculating (41/50)...\n",
      "\n",
      "Calculating (42/50)...\n",
      "\n",
      "Calculating (43/50)...\n",
      "\n",
      "Calculating (44/50)...\n",
      "\n",
      "Calculating (45/50)...\n",
      "\n",
      "Calculating (46/50)...\n",
      "\n",
      "Calculating (47/50)...\n",
      "\n",
      "Calculating (48/50)...\n",
      "\n",
      "Calculating (49/50)...\n",
      "\n",
      "Calculating (50/50)...\n",
      "\n",
      "----------------------------------------------------------\n",
      "Best error ratio:  0.0123333333333\n",
      "Number of neurons in the hidden layer:  30\n",
      "Learning rate:  0.012\n",
      "----------------------------------------------------------\n",
      "Processing time: 2018.86702125 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.clock()\n",
    "param_df, best_param = parameter_testing(df=df, parameter_df=parameter_df)\n",
    "print \"Processing time: {0} minutes\".format((time.clock() - t0)/60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
